{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Improved Belief Model - Colab Training Notebook\n",
        "\n",
        "This notebook is set up to train the Improved Belief Model on Google Colab with optional GPU acceleration.\n",
        "\n",
        "What it does:\n",
        "- Installs dependencies\n",
        "- Loads your project into Colab (upload zip or mount Drive)\n",
        "- Parses existing logs into training states\n",
        "- Trains the improved belief model (with configurable epochs/sample fraction)\n",
        "- Saves the trained weights back to Drive or local runtime\n",
        "\n",
        "Notes:\n",
        "- If using GPU: Runtime → Change runtime type → Hardware accelerator: GPU.\n",
        "- Ensure your logs exist (e.g., `logs/game28/mcts_games` and/or `logs/improved_games`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# Install system and Python dependencies\n",
        "pip -q install --upgrade pip\n",
        "pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "pip -q install tqdm numpy pyyaml\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Mount Google Drive (optional) and set up project\n",
        "USE_DRIVE = True  #@param {type:\"boolean\"}\n",
        "PROJECT_DIR = \"/content/28bot\"  #@param {type:\"string\"}\n",
        "\n",
        "import os, shutil\n",
        "from pathlib import Path\n",
        "\n",
        "if USE_DRIVE:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  DRIVE_BASE = \"/content/drive/MyDrive\"\n",
        "  if not os.path.exists(f\"{DRIVE_BASE}/28bot\"):\n",
        "    os.makedirs(f\"{DRIVE_BASE}/28bot\", exist_ok=True)\n",
        "  PROJECT_DIR = f\"{DRIVE_BASE}/28bot\"\n",
        "\n",
        "print(\"Project dir:\", PROJECT_DIR)\n",
        "Path(PROJECT_DIR).mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Upload repo zip or clone (choose one)\n",
        "MODE = \"upload_zip\"  #@param [\"upload_zip\", \"git_clone\"]\n",
        "GIT_URL = \"\"  #@param {type:\"string\"}\n",
        "\n",
        "import os, zipfile\n",
        "from google.colab import files\n",
        "\n",
        "os.chdir(PROJECT_DIR)\n",
        "\n",
        "if MODE == \"upload_zip\":\n",
        "  print(\"Please upload a zip containing the 28bot_v2 folder and logs/... folders\")\n",
        "  uploaded = files.upload()\n",
        "  for fn in uploaded:\n",
        "    if fn.endswith('.zip'):\n",
        "      with zipfile.ZipFile(fn, 'r') as z:\n",
        "        z.extractall(PROJECT_DIR)\n",
        "      print(\"Unzipped:\", fn)\n",
        "else:\n",
        "  if not GIT_URL:\n",
        "    raise ValueError(\"Provide a GIT_URL or use upload_zip mode\")\n",
        "  # Use shell command via python to avoid lint in this cell\n",
        "  import subprocess\n",
        "  subprocess.run([\"bash\", \"-lc\", f\"git clone {GIT_URL} {PROJECT_DIR}\"])\n",
        "\n",
        "print(\"Project contents:\", os.listdir(PROJECT_DIR)[:20])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Configure training\n",
        "EPOCHS = 20  #@param {type:\"integer\"}\n",
        "SAMPLE_FRACTION = 0.5  #@param {type:\"number\"}\n",
        "LR = 0.001  #@param {type:\"number\"}\n",
        "TRUMP_ONLY = True  #@param {type:\"boolean\"}\n",
        "\n",
        "import random\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#@title Configure training\n",
        "EPOCHS = 20  #@param {type:\"integer\"}\n",
        "SAMPLE_FRACTION = 0.5  #@param {type:\"number\"}\n",
        "LR = 0.001  #@param {type:\"number\"}\n",
        "TRUMP_ONLY = True  #@param {type:\"boolean\"}\n",
        "\n",
        "import random\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Train on GPU with AMP (reads logs/ and saves models/)\n",
        "import os, sys, json, math\n",
        "from pathlib import Path\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# Add project to path\n",
        "sys.path.insert(0, PROJECT_DIR)\n",
        "\n",
        "from belief_model.improved_belief_net import create_improved_belief_model, train_improved_belief_model\n",
        "from belief_model.advanced_parser import extract_all_game_states\n",
        "from train_improved_belief import build_training_data_from_logs\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# Load parsed states\n",
        "dirs = [\n",
        "    os.path.join(PROJECT_DIR, \"logs\", \"game28\", \"mcts_games\"),\n",
        "    os.path.join(PROJECT_DIR, \"logs\", \"improved_games\")\n",
        "]\n",
        "parsed = extract_all_game_states(dirs)\n",
        "print(\"Total parsed states:\", len(parsed))\n",
        "\n",
        "# Sample subset if requested\n",
        "if SAMPLE_FRACTION < 1.0:\n",
        "  k = max(1, int(len(parsed) * SAMPLE_FRACTION))\n",
        "  import random as _r\n",
        "  parsed = _r.sample(parsed, k)\n",
        "  print(\"Sampled states:\", len(parsed))\n",
        "\n",
        "# Build training tuples\n",
        "training = build_training_data_from_logs(parsed)\n",
        "print(\"Training tuples:\", len(training))\n",
        "\n",
        "# Create model\n",
        "model = create_improved_belief_model().to(device)\n",
        "\n",
        "# Optional: trump-only loss wrapper\n",
        "class TrumpOnlyWrapper(nn.Module):\n",
        "  def __init__(self, model):\n",
        "    super().__init__()\n",
        "    self.model = model\n",
        "  def forward(self, game_state, player_id):\n",
        "    return self.model(game_state, player_id)\n",
        "\n",
        "# Minimal trainer with AMP for trump-only\n",
        "def train_trump_only(model, data, epochs=EPOCHS, lr=LR):\n",
        "  opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "  scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
        "  bce = nn.BCELoss()\n",
        "  model.train()\n",
        "  for ep in range(epochs):\n",
        "    total = 0.0\n",
        "    for game_state, pid, targets in data:\n",
        "      opt.zero_grad(set_to_none=True)\n",
        "      with torch.cuda.amp.autocast(enabled=torch.cuda.is_available()):\n",
        "        out = model(game_state, pid)\n",
        "        loss = 0.0\n",
        "        if 'trump' in targets:\n",
        "          target_trump = torch.tensor(targets['trump'], dtype=torch.float32, device=device)\n",
        "          loss = loss + bce(out.trump_suit.to(device), target_trump)\n",
        "      scaler.scale(loss).backward()\n",
        "      scaler.step(opt)\n",
        "      scaler.update()\n",
        "      total += float(loss.item())\n",
        "    if (ep % 5) == 0:\n",
        "      print(f\"Epoch {ep}: loss={total/len(data):.4f}\")\n",
        "  return model\n",
        "\n",
        "if TRUMP_ONLY:\n",
        "  model = train_trump_only(model, training, epochs=EPOCHS, lr=LR)\n",
        "else:\n",
        "  # Fallback to full trainer (CPU-style) if desired\n",
        "  model = train_improved_belief_model(model, training, epochs=EPOCHS, learning_rate=LR)\n",
        "\n",
        "# Save\n",
        "out_dir = os.path.join(PROJECT_DIR, \"models\")\n",
        "Path(out_dir).mkdir(parents=True, exist_ok=True)\n",
        "torch.save(model.state_dict(), os.path.join(out_dir, \"improved_belief_model.pt\"))\n",
        "print(\"Saved:\", os.path.join(out_dir, \"improved_belief_model.pt\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title Configure training\n",
        "EPOCHS = 20  #@param {type:\"integer\"}\n",
        "SAMPLE_FRACTION = 0.5  #@param {type:\"number\"}\n",
        "LR = 0.001  #@param {type:\"number\"}\n",
        "TRUMP_ONLY = True  #@param {type:\"boolean\"}\n",
        "\n",
        "import random\n",
        "random.seed(42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#@title Configure training\n",
        "EPOCHS = 20  #@param {type:\"integer\"}\n",
        "SAMPLE_FRACTION = 0.5  #@param {type:\"number\"}\n",
        "LR = 0.001  #@param {type:\"number\"}\n",
        "TRUMP_ONLY = True  #@param {type:\"boolean\"}\n",
        "\n",
        "import random\n",
        "random.seed(42)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
