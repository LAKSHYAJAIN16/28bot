"""
Exploitability evaluation for Game 28 bidding strategies
"""

import numpy as np
from typing import Dict, List, Tuple, Callable
from tqdm import tqdm
import json
import os

from game28.game_state import Game28State
from game28.constants import *
from ismcts.ismcts_bidding import ISMCTSBidding
from belief_model.belief_net import BeliefNetwork


class ExploitabilityEvaluator:
    """
    Evaluates the exploitability of bidding strategies
    """
    
    def __init__(self, num_games: int = 1000):
        self.num_games = num_games
    
    def evaluate_strategy_exploitability(self, strategy: Callable, 
                                       opponent_strategies: List[Callable]) -> Dict:
        """
        Evaluate exploitability of a strategy against different opponents
        
        Args:
            strategy: The strategy to evaluate
            opponent_strategies: List of opponent strategies to test against
            
        Returns:
            Dictionary with exploitability metrics
        """
        results = {
            'strategy_name': strategy.__name__ if hasattr(strategy, '__name__') else 'Unknown',
            'num_games': self.num_games,
            'opponent_results': {},
            'overall_metrics': {}
        }
        
        # Test against each opponent strategy
        for i, opponent_strategy in enumerate(opponent_strategies):
            opponent_name = opponent_strategy.__name__ if hasattr(opponent_strategy, '__name__') else f'Opponent_{i}'
            
            print(f"Testing against {opponent_name}...")
            
            # Run games
            wins = 0
            total_reward = 0
            bid_success_rate = 0
            avg_bid = 0
            
            for _ in tqdm(range(self.num_games), desc=f"vs {opponent_name}"):
                game_result = self._play_game(strategy, opponent_strategy)
                
                if game_result['winner'] == 'strategy':
                    wins += 1
                
                total_reward += game_result['reward']
                
                if game_result['bid_success']:
                    bid_success_rate += 1
                
                avg_bid += game_result['final_bid']
            
            # Calculate metrics
            win_rate = wins / self.num_games
            avg_reward = total_reward / self.num_games
            bid_success_rate = bid_success_rate / self.num_games
            avg_bid = avg_bid / self.num_games
            
            results['opponent_results'][opponent_name] = {
                'win_rate': win_rate,
                'avg_reward': avg_reward,
                'bid_success_rate': bid_success_rate,
                'avg_bid': avg_bid
            }
        
        # Calculate overall metrics
        results['overall_metrics'] = self._calculate_overall_metrics(results['opponent_results'])
        
        return results
    
    def _play_game(self, strategy: Callable, opponent_strategy: Callable) -> Dict:
        """Play a single game between two strategies"""
        game_state = Game28State()
        
        # Play bidding phase
        while not game_state.game_over and game_state.phase == GamePhase.BIDDING:
            current_player = game_state.current_player
            
            if current_player == 0:  # Strategy player
                action = strategy(game_state, current_player)
            else:  # Opponent player
                action = opponent_strategy(game_state, current_player)
            
            # Apply action
            game_state.make_bid(current_player, action)
        
        # Determine winner
        if game_state.bidder is not None:
            bidder_team = 'A' if game_state.bidder in TEAM_A else 'B'
            team_score = game_state.team_scores[bidder_team]
            winning_bid = game_state.winning_bid
            
            bid_success = team_score >= winning_bid
            final_bid = winning_bid
            
            # Determine winner (simplified - just based on bid success)
            if game_state.bidder == 0:  # Strategy player was bidder
                winner = 'strategy' if bid_success else 'opponent'
                reward = 1.0 if bid_success else -1.0
            else:  # Opponent was bidder
                winner = 'opponent' if bid_success else 'strategy'
                reward = -1.0 if bid_success else 1.0
        else:
            # No one bid - tie
            winner = 'tie'
            reward = 0.0
            bid_success = False
            final_bid = 0
        
        return {
            'winner': winner,
            'reward': reward,
            'bid_success': bid_success,
            'final_bid': final_bid,
            'bidder': game_state.bidder
        }
    
    def _calculate_overall_metrics(self, opponent_results: Dict) -> Dict:
        """Calculate overall exploitability metrics"""
        win_rates = [result['win_rate'] for result in opponent_results.values()]
        avg_rewards = [result['avg_reward'] for result in opponent_results.values()]
        bid_success_rates = [result['bid_success_rate'] for result in opponent_results.values()]
        
        return {
            'avg_win_rate': np.mean(win_rates),
            'min_win_rate': np.min(win_rates),
            'max_win_rate': np.max(win_rates),
            'win_rate_std': np.std(win_rates),
            'avg_reward': np.mean(avg_rewards),
            'avg_bid_success_rate': np.mean(bid_success_rates),
            'exploitability': 1.0 - np.min(win_rates)  # How much can be exploited
        }


def evaluate_exploitability(strategies: List[Callable], 
                          num_games: int = 1000,
                          save_results: bool = True,
                          results_dir: str = "results/exploitability") -> Dict:
    """
    Evaluate exploitability of multiple strategies
    
    Args:
        strategies: List of strategies to evaluate
        num_games: Number of games per evaluation
        save_results: Whether to save results to file
        results_dir: Directory to save results
        
    Returns:
        Dictionary with all evaluation results
    """
    
    if save_results:
        os.makedirs(results_dir, exist_ok=True)
    
    evaluator = ExploitabilityEvaluator(num_games=num_games)
    all_results = {}
    
    # Evaluate each strategy against all others
    for i, strategy in enumerate(strategies):
        print(f"\nEvaluating strategy {i+1}/{len(strategies)}: {strategy.__name__}")
        
        # Use other strategies as opponents
        opponents = [s for j, s in enumerate(strategies) if j != i]
        
        results = evaluator.evaluate_strategy_exploitability(strategy, opponents)
        all_results[strategy.__name__] = results
        
        # Save individual results
        if save_results:
            filename = f"{strategy.__name__}_exploitability.json"
            filepath = os.path.join(results_dir, filename)
            with open(filepath, 'w') as f:
                json.dump(results, f, indent=2)
    
    # Create summary
    summary = create_exploitability_summary(all_results)
    
    if save_results:
        summary_filepath = os.path.join(results_dir, "exploitability_summary.json")
        with open(summary_filepath, 'w') as f:
            json.dump(summary, f, indent=2)
    
    return all_results


def create_exploitability_summary(results: Dict) -> Dict:
    """Create summary of exploitability results"""
    summary = {
        'strategies': [],
        'comparison_matrix': {},
        'ranking': []
    }
    
    strategy_names = list(results.keys())
    summary['strategies'] = strategy_names
    
    # Create comparison matrix
    for strategy_name in strategy_names:
        summary['comparison_matrix'][strategy_name] = {}
        for opponent_name in strategy_names:
            if strategy_name == opponent_name:
                summary['comparison_matrix'][strategy_name][opponent_name] = 0.5
            else:
                # Find win rate against this opponent
                opponent_results = results[strategy_name]['opponent_results']
                if opponent_name in opponent_results:
                    win_rate = opponent_results[opponent_name]['win_rate']
                    summary['comparison_matrix'][strategy_name][opponent_name] = win_rate
                else:
                    summary['comparison_matrix'][strategy_name][opponent_name] = 0.0
    
    # Create ranking based on overall performance
    strategy_scores = []
    for strategy_name in strategy_names:
        overall_metrics = results[strategy_name]['overall_metrics']
        score = overall_metrics['avg_win_rate']
        strategy_scores.append((strategy_name, score))
    
    # Sort by score (descending)
    strategy_scores.sort(key=lambda x: x[1], reverse=True)
    summary['ranking'] = [name for name, score in strategy_scores]
    
    return summary


# Example strategies for testing
def random_strategy(game_state: Game28State, player_id: int) -> int:
    """Random bidding strategy"""
    legal_bids = game_state.get_legal_bids(player_id)
    if legal_bids:
        return np.random.choice(legal_bids)
    return -1


def conservative_strategy(game_state: Game28State, player_id: int) -> int:
    """Conservative bidding strategy"""
    hand = game_state.hands[player_id]
    hand_strength = sum(CARD_VALUES[card.rank] for card in hand) / TOTAL_POINTS
    
    if hand_strength > 0.5:
        # Strong hand - bid moderately
        return min(game_state.current_bid + 1, MAX_BID)
    else:
        # Weak hand - pass
        return -1


def aggressive_strategy(game_state: Game28State, player_id: int) -> int:
    """Aggressive bidding strategy"""
    hand = game_state.hands[player_id]
    hand_strength = sum(CARD_VALUES[card.rank] for card in hand) / TOTAL_POINTS
    
    if hand_strength > 0.3:
        # Moderate+ hand - bid aggressively
        return min(game_state.current_bid + 2, MAX_BID)
    else:
        return -1


if __name__ == "__main__":
    # Example usage
    strategies = [random_strategy, conservative_strategy, aggressive_strategy]
    
    results = evaluate_exploitability(
        strategies=strategies,
        num_games=500,
        save_results=True
    )
    
    print("\nExploitability Evaluation Complete!")
    print("Results saved to results/exploitability/")
